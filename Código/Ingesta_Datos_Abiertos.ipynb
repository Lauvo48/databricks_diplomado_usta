{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1585077d-1079-4b46-aa30-a32727e77e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Cuaderno de Ingesta de Datos\n",
    "\n",
    "En este bloque traeremos la información de datos abiertos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49045ceb-4efe-45c5-8ed9-a164497792ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paso 1: Descargar los datos con requests y leerlos en pandas\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "url_secop = \"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit=100000\"\n",
    "url_men = \"https://www.datos.gov.co/resource/nudc-7mev.csv?$limit=100000\"\n",
    " \n",
    "# Descargar contenido\n",
    "response_secop = requests.get(url_secop)\n",
    "response_men = requests.get(url_men)\n",
    "\n",
    "# Convertir contenido a pandas usando StringIO\n",
    "df_secop_pd = pd.read_csv(StringIO(response_secop.text))\n",
    "df_men_pd = pd.read_csv(StringIO(response_men.text))\n",
    "\n",
    "# Convertir pandas a Spark\n",
    "df_secop = spark.createDataFrame(df_secop_pd)\n",
    "df_men = spark.createDataFrame(df_men_pd)\n",
    "\n",
    "# Mostrar en Databricks\n",
    "display(df_secop)\n",
    "display(df_men)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c8347b-45d3-450f-b074-12f0de5145d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop.count()\n",
    "df_men.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d4896a-b5d3-49ff-b1a6-0036a7943fb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d4192b-d9d2-4e3f-846d-b29cccd7d4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS main.diplomado_datos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c61de2f-f339-4cdf-9707-0712d30dc4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.secop\")\n",
    "df_men.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.men_estadisticas\")\n",
    "\n",
    "print(\"¡Tablas guardadas exitosamente en el catálogo 'main', esquema 'diplomado_datos'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3673c873-0441-4cab-8db1-b80348d36c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paso 1: Descargar los datos con requests y leerlos en pandas\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "url_secop = \"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit=100000&$offset=100000\"\n",
    " \n",
    "# Descargar contenido\n",
    "response_secop = requests.get(url_secop)\n",
    "\n",
    "# Convertir contenido a pandas usando StringIO\n",
    "df_secop_pd = pd.read_csv(\n",
    "    StringIO(response_secop.text),\n",
    "    delimiter=',',\n",
    "    header=0,\n",
    "    dtype=str,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Convertir pandas a Spark\n",
    "df_secop = spark.createDataFrame(df_secop_pd)\n",
    "\n",
    "# Mostrar en Databricks\n",
    "display(df_secop)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3030bac8-b933-4604-a858-ed94a266a51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9315f1-b5fc-411c-b4c1-12d28ff9f89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "target_schema = spark.table(\"main.diplomado_datos.secop\").schema\n",
    "\n",
    "df_secop_aligned = df_secop.select(\n",
    "    [col(field.name).cast(field.dataType) for field in target_schema.fields]\n",
    ")\n",
    "\n",
    "\n",
    "df_secop_aligned.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"main.diplomado_datos.secop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8763c25b-57f9-4937-bdb4-4e915ff1ebd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_registros = 19446266\n",
    "offset_inicial = 200000\n",
    "limite = 100000\n",
    "paginas_faltantes = ((total_registros - offset_inicial) // limite) + 1\n",
    "\n",
    "print(f\"Quedan {paginas_faltantes} bloques por descargar...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9426f816-8703-46ed-800f-e06c9083f193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, trim, expr\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "for i in range(paginas_faltantes):\n",
    "    offset = offset_inicial + (i * limite)\n",
    "    url = f\"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit={limite}&$offset={offset}\"\n",
    "    \n",
    "    print(f\"Descargando página {i+1} con offset {offset}\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        df_secop_pd = pd.read_csv(\n",
    "            StringIO(response.text),\n",
    "            dtype=str,\n",
    "            low_memory=False\n",
    "        )\n",
    "        \n",
    "        if not df_secop_pd.empty:\n",
    "            df_secop = spark.createDataFrame(df_secop_pd)\n",
    "            \n",
    "            target_schema = spark.table(\"main.diplomado_datos.secop\").schema\n",
    "            \n",
    "            invalid_values = [\"NO DEFINIDO\", \"NO APLICA\", \"N/A\", \"SIN DATO\", \"NULL\", \"S/I\", \"\", \"NO_REGISTRA\"]\n",
    "            \n",
    "            # Limpiar TODAS las columnas numéricas según el schema de la Delta table\n",
    "            for field in target_schema.fields:\n",
    "                col_name = field.name\n",
    "                data_type = field.dataType.typeName()\n",
    "                \n",
    "                if col_name in df_secop.columns:\n",
    "                    if data_type in [\"bigint\", \"int\"]:\n",
    "                        df_secop = df_secop.withColumn(\n",
    "                            col_name,\n",
    "                            when(\n",
    "                                (trim(col(col_name)).rlike(\"^[0-9]+$\")) &\n",
    "                                (~trim(col(col_name)).isin(invalid_values)),\n",
    "                                col(col_name).cast(\"bigint\")\n",
    "                            ).otherwise(None)\n",
    "                        )\n",
    "                    \n",
    "                    elif data_type in [\"double\", \"float\", \"decimal\"]:\n",
    "                        df_secop = df_secop.withColumn(\n",
    "                            col_name,\n",
    "                            when(\n",
    "                                (trim(col(col_name)).rlike(\"^[0-9]+([.][0-9]+)?$\")) &\n",
    "                                (~trim(col(col_name)).isin(invalid_values)),\n",
    "                                col(col_name).cast(\"double\")\n",
    "                            ).otherwise(None)\n",
    "                        )\n",
    "                    else:\n",
    "                        df_secop = df_secop.withColumn(\n",
    "                            col_name,\n",
    "                            col(col_name).cast(field.dataType)\n",
    "                        )\n",
    "            \n",
    "            # Alinear DataFrame con schema\n",
    "            df_secop_aligned = df_secop.select(\n",
    "                [\n",
    "                    col(field.name).cast(field.dataType)\n",
    "                    if field.name in df_secop.columns\n",
    "                    else expr(\"NULL\").cast(field.dataType).alias(field.name)\n",
    "                    for field in target_schema.fields\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            df_secop_aligned.write.format(\"delta\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .option(\"mergeSchema\", \"true\") \\\n",
    "                .saveAsTable(\"main.diplomado_datos.secop\")\n",
    "            \n",
    "            print(f\"✓ Página {i+1} almacenada con {df_secop_pd.shape[0]} filas\")\n",
    "        else:\n",
    "            print(f\"⚠️ Página {i+1} llegó vacía. Posiblemente sin más datos.\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"⚠️ Error HTTP {response.status_code} en página {i+1}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5568989096625463,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingesta_Datos_Abiertos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
